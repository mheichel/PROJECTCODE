import polars as pl
import plotly.graph_objs as go
import geopandas as gpd
from shapely.geometry import Point
import folium
from folium.plugins import HeatMap
from tqdm import tqdm
import pandas as pd
import glob

def load_and_preprocess_data(file_pattern):
    files = glob.glob(file_pattern)
    data = {}
    for file in tqdm(files, desc="Loading and preprocessing data"):
        df = pl.read_csv(file)
        df = df.with_columns([
            pl.col("Date").str.strptime(pl.Date, fmt="%Y-%m-%d"),
            pl.arange(1, pl.count("API 14") + 1).over("API 14").alias("Normalized Month")
        ])
        df = df.sort(["API 14", "Date"])
        df = df.filter(pl.col("Normalized Month") <= 300)  # Cut off data at 300 months
        month_count = int(file.split('_')[2])
        df = df.with_columns([
            pl.col("Oil Production (BBL/M)").cumsum().over("API 14").alias("Cumulative Production"),
            pl.col("Oil Forecast (BBL/M)").cumsum().over("API 14").alias("Cumulative Forecast")
        ])
        data[month_count] = df
    return data

def filter_valid_wells(data):
    api_60 = data[60]["API 14"].unique().to_list() if 60 in data else []
    api_6 = data[6]["API 14"].unique().to_list() if 6 in data else []
    valid_apis = set(api_6).intersection(api_60)
    
    filtered_data = {}
    for month, df in data.items():
        filtered_data[month] = df.filter(pl.col("API 14").is_in(valid_apis))
    return filtered_data

def aggregate_data(data):
    aggregated_data = {}
    for month, df in tqdm(data.items(), desc="Aggregating data"):
        aggregated_df = df.groupby("Normalized Month").agg([
            pl.col("Oil Production (BBL/M)").mean().alias("Oil Production (BBL/M)"),
            pl.col("Cumulative Production").mean().alias("Cumulative Production"),
            pl.col("Oil Forecast (BBL/M)").mean().alias("Oil Forecast (BBL/M)"),
            pl.col("Cumulative Forecast").mean().alias("Cumulative Forecast")
        ])
        aggregated_data[month] = aggregated_df.to_pandas()
    return aggregated_data

def load_wells_data(filename, columns):
    df = pl.read_csv(filename, columns=columns)
    df = df.rename({"Surface Longitude": "longitude", "Surface Latitude": "latitude"})
    df = df.filter(pl.col("latitude") > 0.1)
    for col in columns[3:]:
        df = df.filter((pl.col(col) > 0.1) & (pl.col(col) < df[col].quantile(0.95)))
    return df

def load_geo_data(df, shapefile):
    geometry = [Point(xy) for xy in zip(df["longitude"], df["latitude"])]
    geo_df = gpd.GeoDataFrame(df.to_pandas(), geometry=geometry)
    geo_df.set_crs(epsg=4326, inplace=True)
    shape_data = gpd.read_file(shapefile)
    shape_data.to_crs(epsg=4326, inplace=True)
    joined = gpd.sjoin(geo_df, shape_data, how='left', predicate='within')
    return joined, shape_data

def calculate_avg_values(joined, shape_data, columns):
    avg_col_names = []
    for col in columns[3:]:
        months = col.split()[2]
        avg_col_name = f'avg_{months}_months'
        shape_data[avg_col_name] = joined.groupby('index_right')[col].mean()
        avg_col_names.append(avg_col_name)
    return shape_data, avg_col_names

def create_colormaps(shape_data, avg_col_names):
    colormaps = {}
    for col in avg_col_names:
        colormaps[col] = {
            'colors': ['blue', 'green', 'yellow', 'orange', 'red'],
            'vmin': shape_data[col].min(),
            'vmax': 150,
            'caption': f'EUR Value ({col})'
        }
    return colormaps

def plot_production(aggregated_data, selected_month):
    data = aggregated_data[selected_month]
    scatter_data = go.Scatter(
        x=data['Normalized Month'],
        y=data['Oil Production (BBL/M)'],
        mode='markers+lines',
        name='Production'
    )
    layout = go.Layout(
        title="Production Data",
        xaxis=dict(title='Normalized Month'),
        yaxis=dict(title='Production'),
        template='plotly_dark',
        hovermode='x'
    )
    fig = go.Figure(data=[scatter_data], layout=layout)
    fig.show()

def plot_cumulative_production(aggregated_data, selected_month):
    data = aggregated_data[selected_month]
    cumulative_data = go.Scatter(
        x=data['Normalized Month'],
        y=data['Cumulative Production'],
        mode='markers+lines',
        name='Cumulative Production'
    )
    layout = go.Layout(
        title="Cumulative Production",
        xaxis=dict(title='Normalized Month'),
        yaxis=dict(title='Cumulative Production'),
        template='plotly_dark',
        hovermode='x'
    )
    fig = go.Figure(data=[cumulative_data], layout=layout)
    fig.show()

def plot_map(shape_data, avg_col_names):
    m = folium.Map(location=[mean_latitude, mean_longitude], zoom_start=10)
    folium.Choropleth(
        geo_data=shape_data.to_json(),
        name='choropleth',
        data=shape_data,
        columns=['index_right'] + avg_col_names,
        key_on='feature.id',
        fill_color='YlOrRd',
        fill_opacity=0.7,
        line_opacity=0.2,
        legend_name='EUR Value'
    ).add_to(m)
    folium.LayerControl().add_to(m)
    return m

# Main execution
print("Starting data processing...")

file_pattern = 'Delaware_NM_*_Months_Combined_Monthly.csv'
data_dict = load_and_preprocess_data(file_pattern)
print("Data loaded and preprocessed.")

filtered_data_dict = filter_valid_wells(data_dict)
print("Valid wells filtered.")

aggregated_data = aggregate_data(filtered_data_dict)
print("Data aggregated.")

# Load well data
columns = [
    'API 14', 'Surface Longitude', 'Surface Latitude',
    'EUR/PLL (BBL/FT) 6 Months', 'EUR/PLL (BBL/FT) 12 Months', 'EUR/PLL (BBL/FT) 18 Months',
    'EUR/PLL (BBL/FT) 24 Months', 'EUR/PLL (BBL/FT) 30 Months', 'EUR/PLL (BBL/FT) 36 Months',
    'EUR/PLL (BBL/FT) 42 Months', 'EUR/PLL (BBL/FT) 48 Months', 'EUR/PLL (BBL/FT) 54 Months',
    'EUR/PLL (BBL/FT) 60 Months'
]
wells_df = load_wells_data('AllWellsNoError.csv', columns)
print("Well data loaded.")

# Load and process geospatial data
print("Loading and processing first shapefile...")
joined, shape_data = load_geo_data(wells_df, 'PLSSFirstDivision.geojson')
shape_data, avg_col_names = calculate_avg_values(joined, shape_data, columns)
print("First shapefile processed.")

print("Loading and processing second shapefile...")
joined2, shape_data2 = load_geo_data(wells_df, 'PLSSTownship.geojson')
shape_data2, avg_col_names = calculate_avg_values(joined2, shape_data2, columns)
print("Second shapefile processed.")

# Calculate mean latitude and longitude for map centering
mean_latitude = wells_df['latitude'].mean()
mean_longitude = wells_df['longitude'].mean()
print("Mean latitude and longitude calculated.")

# Plotting the map
m = plot_map(shape_data, avg_col_names)
m

# Plotting production data for a selected month (example: 60 months)
selected_month = 60
plot_production(aggregated_data, selected_month)
plot_cumulative_production(aggregated_data, selected_month)
