import pandas as pd
import geopandas as gpd
import numpy as np
from shapely.geometry import Point
import branca.colormap as cm
import dash
from dash import dcc, html
from dash.dependencies import Input, Output

# Load the wells_df
columns = [
    'API 14', 'Surface Longitude', 'Surface Latitude',
    'EUR/PLL (BBL/FT) 6 Months', 'EUR/PLL (BBL/FT) 12 Months', 'EUR/PLL (BBL/FT) 18 Months',
    'EUR/PLL (BBL/FT) 24 Months', 'EUR/PLL (BBL/FT) 30 Months', 'EUR/PLL (BBL/FT) 36 Months',
    'EUR/PLL (BBL/FT) 42 Months', 'EUR/PLL (BBL/FT) 48 Months', 'EUR/PLL (BBL/FT) 54 Months',
    'EUR/PLL (BBL/FT) 60 Months', 'MyIntervalsPlus', 'MyPLLIntervals', 'MyVintages'
]

wells_df = pd.read_csv('AllWellsNoError.csv', usecols=columns)
wells_df = wells_df.rename(columns={'Surface Longitude': 'longitude', 'Surface Latitude': 'latitude'})
wells_df = wells_df[wells_df['latitude'] > 0.1]

for col in columns[3:13]:
    wells_df = wells_df[wells_df[col] > 0.1]
    wells_df = wells_df[wells_df[col] < np.nanpercentile(wells_df[col], 95)]

wells_df = wells_df.reset_index()

# Calculate mean latitude and longitude
mean_latitude = wells_df['latitude'].mean()
mean_longitude = wells_df['longitude'].mean()

# Convert well data to GeoDataFrame
geometry = [Point(xy) for xy in zip(wells_df['longitude'], wells_df['latitude'])]
geo_data = gpd.GeoDataFrame(wells_df, geometry=geometry)

# Set the CRS to WGS84 (EPSG:4326)
geo_data.set_crs(epsg=4326, inplace=True)

# Load the township boundaries shapefile
shape_data = gpd.read_file('PLSSFirstDivision.geojson')  # Replace with your shapefile path

# Ensure the CRS for the township boundaries is set to WGS84
shape_data.to_crs(epsg=4326, inplace=True)

# Spatial join to assign points to township polygons
joined = gpd.sjoin(geo_data, shape_data, how='left', op='within')

# Calculate average values for each township polygon
avg_col_names = []

for col in columns[3:13]:
    months = col.split()[2]
    avg_col_name = f'avg_{months}_months'
    shape_data[avg_col_name] = joined.groupby('index_right')[col].mean()
    avg_col_names.append(avg_col_name)

# Drop sections where all the average values are 0
shape_data = shape_data[(shape_data[avg_col_names] > 0).any(axis=1)]

# Create colormaps for each time period
colormaps = {}

for col in avg_col_names:
    months = col[4]
    avg_col_name = col
    colormaps[avg_col_name] = cm.LinearColormap(colors=['blue', 'green', 'yellow', 'orange', 'red'],
                                                vmin=shape_data[avg_col_name].min(),
                                                vmax=150,
                                                caption=f'EUR Value ({col})')

# Create GeoJSON data for each dataset
geojson_data = {}

for col in avg_col_names:
    months = col
    avg_col_name = col
    geojson_data[avg_col_name] = shape_data[['geometry', avg_col_name]].to_json()

# Load the second shapefile
shape_data2 = gpd.read_file('PLSSTownship.geojson')  # Replace with your second shapefile path
shape_data2.set_crs(epsg=4326, inplace=True)

# Spatial join to assign points to township polygons for the second shapefile
joined2 = gpd.sjoin(geo_data, shape_data2, how='left', op='within')

avg_col_names = []

for col in columns[3:13]:
    months = col.split()[2]
    avg_col_name = f'avg_{months}_months'
    shape_data2[avg_col_name] = joined2.groupby('index_right')[col].mean()
    avg_col_names.append(avg_col_name)

# Drop sections where all the average values are 0 for the second shapefile
shape_data2 = shape_data2[(shape_data2[avg_col_names] > 0).any(axis=1)]

# Create colormaps and GeoJSON data for the second shapefile
colormaps2 = {}
geojson_data2 = {}

for col in avg_col_names:
    months = col
    avg_col_name = f'{col}'
    colormaps2[avg_col_name] = cm.LinearColormap(colors=['blue', 'green', 'yellow', 'orange', 'red'],
                                                 vmin=shape_data2[avg_col_name].min(),
                                                 vmax=150,
                                                 caption=f'EUR Value ({months})')
    geojson_data2[avg_col_name] = shape_data2[['geometry', avg_col_name]].to_json()

# Dash app setup
app = dash.Dash(__name__)

app.layout = html.Div([
    html.H1("Well Data Heatmap"),
    dcc.Dropdown(
        id='intervals-dropdown',
        options=[{'label': interval, 'value': interval} for interval in wells_df['MyIntervalsPlus'].unique()],
        multi=True,
        placeholder="Select Intervals"
    ),
    dcc.Dropdown(
        id='pllintervals-dropdown',
        options=[{'label': interval, 'value': interval} for interval in wells_df['MyPLLIntervals'].unique()],
        multi=True,
        placeholder="Select PLL Intervals"
    ),
    dcc.Dropdown(
        id='vintages-dropdown',
        options=[{'label': vintage, 'value': vintage} for vintage in wells_df['MyVintages'].unique()],
        multi=True,
        placeholder="Select Vintages"
    ),
    dcc.Graph(id='heatmap')
])

@app.callback(
    Output('heatmap', 'figure'),
    [Input('intervals-dropdown', 'value'),
     Input('pllintervals-dropdown', 'value'),
     Input('vintages-dropdown', 'value')]
)
def update_heatmap(selected_intervals, selected_pllintervals, selected_vintages):
    filtered_df = wells_df.copy()

    if selected_intervals:
        filtered_df = filtered_df[filtered_df['MyIntervalsPlus'].isin(selected_intervals)]
    if selected_pllintervals:
        filtered_df = filtered_df[filtered_df['MyPLLIntervals'].isin(selected_pllintervals)]
    if selected_vintages:
        filtered_df = filtered_df[filtered_df['MyVintages'].isin(selected_vintages)]
    
    heatmap_data = filtered_df.groupby(['MyIntervalsPlus', 'MyPLLIntervals', 'MyVintages']).size().reset_index(name='Counts')
    
    fig = px.density_heatmap(
        heatmap_data,
        x='MyIntervalsPlus',
        y='MyVintages',
        z='Counts',
        color_continuous_scale='Viridis'
    )
    
    return fig

if __name__ == '__main__':
    app.run_server(debug=True)
